<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advisor Booking Agent - Complete Voice Interface (STT + TTS)</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            width: 100%;
            max-width: 500px;
            padding: 40px;
            text-align: center;
        }

        .header {
            margin-bottom: 40px;
        }

        .header h1 {
            font-size: 28px;
            color: #333;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 16px;
            color: #666;
        }

        .mic-container {
            margin: 40px 0;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 48px;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto;
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.5);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
            animation: pulse 1.5s infinite;
            box-shadow: 0 10px 30px rgba(231, 76, 60, 0.4);
        }

        .mic-button.processing {
            background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
            animation: spin 2s linear infinite;
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
        }

        @keyframes spin {
            from {
                transform: rotate(0deg);
            }
            to {
                transform: rotate(360deg);
            }
        }

        .status {
            margin-top: 30px;
            font-size: 18px;
            color: #666;
            min-height: 30px;
            font-weight: 500;
        }

        .status.listening {
            color: #e74c3c;
        }

        .status.processing {
            color: #f39c12;
        }

        .status.speaking {
            color: #667eea;
        }

        .chat-history {
            margin-top: 20px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 10px;
            min-height: 100px;
            max-height: 400px;
            overflow-y: auto;
            text-align: left;
        }

        .message {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
        }

        .message:last-child {
            margin-bottom: 0;
        }

        .message.user {
            background: #e3f2fd;
            border-left: 3px solid #667eea;
        }

        .message.agent {
            background: #f1f8e9;
            border-left: 3px solid #4caf50;
        }

        .message-bubble {
            color: #333;
            line-height: 1.5;
            font-size: 14px;
        }

        .error {
            margin-top: 20px;
            padding: 15px;
            background: #fee;
            border-radius: 10px;
            color: #c33;
            font-size: 14px;
        }

        .info {
            margin-top: 30px;
            padding: 15px;
            background: #e8f4f8;
            border-radius: 10px;
            font-size: 12px;
            color: #555;
            line-height: 1.6;
        }

        .info strong {
            color: #333;
        }

        .link-to-text {
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
        }

        .link-to-text a {
            color: #667eea;
            text-decoration: none;
            font-size: 14px;
        }

        .link-to-text a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Complete Voice Agent</h1>
            <p>Speak to book, reschedule, or cancel (STT + TTS)</p>
        </div>

        <div class="mic-container">
            <button id="micButton" class="mic-button" onclick="toggleRecording()">
                üé§
            </button>
        </div>

        <div class="status" id="status">Click the microphone to start</div>

        <div class="chat-history" id="chatHistory" style="display: none;"></div>

        <div class="error" id="errorContainer" style="display: none;"></div>

        <div class="info">
            <strong>How to use:</strong><br>
            ‚Ä¢ Click the microphone button<br>
            ‚Ä¢ Allow microphone access when prompted<br>
            ‚Ä¢ Speak your request clearly<br>
            ‚Ä¢ Listen to the agent's voice response<br>
            ‚Ä¢ Continue the conversation naturally<br><br>
            <strong>Browser:</strong> Works best in Chrome or Edge<br>
            <strong>Features:</strong> Speech-to-Text + Text-to-Speech
        </div>

        <div class="link-to-text">
            <a href="/">Switch to text chat</a> | 
            <a href="/voice.html">Switch to voice-only (STT)</a>
        </div>
    </div>

    <!-- Audio element for TTS playback -->
    <audio id="ttsAudio" style="display: none;" preload="auto" playsinline></audio>

    <script>
        let recognition = null;
        let isRecording = false;
        let sessionId = null;
        let isProcessing = false;
        let recognitionTimeout = null;

        // Initialize session
        async function initSession() {
            try {
                const response = await fetch('/api/session', {
                    method: 'POST'
                });
                const data = await response.json();
                sessionId = data.sessionId;
                console.log('Session initialized:', sessionId);
            } catch (error) {
                console.error('Error initializing session:', error);
                showError('Failed to initialize session. Please refresh the page.');
            }
        }

        // Initialize Web Speech API
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                try {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    recognition = new SpeechRecognition();
                    
                    recognition.continuous = false;
                    recognition.interimResults = false;
                    recognition.lang = 'en-US';
                    recognition.maxAlternatives = 1;
                    
                    console.log('Speech recognition initialized successfully');
                } catch (error) {
                    console.error('Error initializing speech recognition:', error);
                    showError('Failed to initialize speech recognition. Please refresh the page.');
                    return;
                }

                recognition.onstart = () => {
                    console.log('Speech recognition started successfully');
                    updateStatus('Listening... Speak now', 'listening');
                    isRecording = true;
                    
                    // Set timeout - if no result after 10 seconds, stop and show error
                    recognitionTimeout = setTimeout(() => {
                        if (isRecording) {
                            console.warn('Recognition timeout - no speech detected');
                            stopRecording();
                            showError('No speech detected. Please try speaking again.');
                            updateStatus('Click the microphone to try again', '');
                        }
                    }, 10000); // 10 second timeout
                };

                recognition.onresult = async (event) => {
                    console.log('Speech recognition result received:', event);
                    
                    // Clear timeout since we got a result
                    if (recognitionTimeout) {
                        clearTimeout(recognitionTimeout);
                        recognitionTimeout = null;
                    }
                    
                    if (!event.results || event.results.length === 0) {
                        console.warn('No results in recognition event');
                        stopRecording();
                        showError('No speech detected. Please try speaking again.');
                        updateStatus('Click the microphone to try again', '');
                        return;
                    }
                    
                    const transcript = event.results[0][0].transcript;
                    const confidence = event.results[0][0].confidence || 0;
                    console.log('Transcribed:', transcript, 'Confidence:', confidence);
                    
                    if (!transcript || transcript.trim().length === 0) {
                        console.warn('Empty transcript received');
                        stopRecording();
                        showError('No speech detected. Please try speaking again.');
                        updateStatus('Click the microphone to try again', '');
                        return;
                    }
                    
                    // Show user transcript
                    showTranscript(transcript, 'user');
                    
                    // Stop recording
                    stopRecording();
                    
                    // If transcript contains something that looks like a booking code, 
                    // show it more prominently
                    const codePattern = /[A-Z]{2}[\s-]?[A-Z0-9]{4}/i;
                    if (codePattern.test(transcript)) {
                        updateStatus('Processing booking code...', 'processing');
                    }
                    
                    // Send to backend
                    await sendMessage(transcript);
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error, event);
                    
                    // Clear timeout on error
                    if (recognitionTimeout) {
                        clearTimeout(recognitionTimeout);
                        recognitionTimeout = null;
                    }
                    
                    stopRecording();
                    
                    let errorMessage = 'Sorry, I couldn\'t understand that.';
                    if (event.error === 'no-speech') {
                        errorMessage = 'No speech detected. Please speak clearly and try again.';
                    } else if (event.error === 'audio-capture') {
                        errorMessage = 'Microphone not found. Please check your microphone connection.';
                    } else if (event.error === 'not-allowed') {
                        errorMessage = 'Microphone permission denied. Please allow microphone access in your browser settings and refresh the page.';
                    } else if (event.error === 'aborted') {
                        errorMessage = 'Recording was interrupted. Please try again.';
                    } else if (event.error === 'network') {
                        errorMessage = 'Network error. Please check your internet connection.';
                    } else {
                        errorMessage = `Error: ${event.error}. Please try again.`;
                    }
                    
                    showError(errorMessage);
                    updateStatus('Click the microphone to try again', '');
                };

                recognition.onend = () => {
                    console.log('Speech recognition ended');
                    
                    // Clear timeout
                    if (recognitionTimeout) {
                        clearTimeout(recognitionTimeout);
                        recognitionTimeout = null;
                    }
                    
                    isRecording = false;
                    updateMicButton('');
                    
                    // Only update status if we're not processing a result
                    if (!isProcessing) {
                        updateStatus('Click the microphone to speak again', '');
                    }
                };
            } else {
                showError('Speech recognition is not supported in your browser. Please use Chrome or Edge.');
                document.getElementById('micButton').disabled = true;
            }
        }

        function toggleRecording() {
            console.log('Toggle recording called. isRecording:', isRecording, 'isProcessing:', isProcessing);
            
            if (isProcessing) {
                console.log('Cannot toggle: currently processing');
                showError('Please wait for the current request to complete.');
                return; // Don't allow recording while processing
            }

            if (isRecording) {
                console.log('Stopping recording...');
                stopRecording();
            } else {
                console.log('Starting recording...');
                startRecording();
            }
        }

        function startRecording() {
            if (!recognition) {
                initSpeechRecognition();
            }

            if (!recognition) {
                showError('Speech recognition is not available. Please use Chrome or Edge browser.');
                return;
            }

            if (isRecording) {
                console.log('Already recording, ignoring start request');
                return;
            }

            if (isProcessing) {
                console.log('Currently processing, cannot start recording');
                return;
            }

            try {
                console.log('Starting speech recognition...');
                recognition.start();
                isRecording = true;
                updateMicButton('recording');
                hideError();
                updateStatus('Listening... Speak now', 'listening');
            } catch (error) {
                console.error('Error starting recognition:', error);
                isRecording = false;
                updateMicButton('');
                
                let errorMsg = 'Failed to start recording. ';
                if (error.name === 'InvalidStateError') {
                    errorMsg += 'Recognition is already running. Please wait.';
                } else if (error.name === 'NotAllowedError') {
                    errorMsg += 'Microphone permission denied. Please allow microphone access in your browser settings.';
                } else {
                    errorMsg += 'Please try again.';
                }
                showError(errorMsg);
                updateStatus('Click the microphone to try again', '');
            }
        }

        function stopRecording() {
            if (recognition && isRecording) {
                try {
                    console.log('Stopping speech recognition...');
                    recognition.stop();
                } catch (error) {
                    console.error('Error stopping recognition:', error);
                }
            }
            isRecording = false;
            updateMicButton('');
        }

        function updateMicButton(state) {
            const micButton = document.getElementById('micButton');
            micButton.className = 'mic-button';
            
            if (state === 'recording') {
                micButton.classList.add('recording');
                micButton.innerHTML = '‚èπÔ∏è';
            } else if (state === 'processing') {
                micButton.classList.add('processing');
                micButton.innerHTML = '‚è≥';
            } else {
                micButton.innerHTML = 'üé§';
            }
        }

        function updateStatus(text, className = '') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = text;
            statusEl.className = 'status ' + className;
        }

        // Function to show transcript in the conversation history
        function showTranscript(text, type = 'user') {
            const chatHistory = document.getElementById('chatHistory');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;

            const bubble = document.createElement('div');
            bubble.className = 'message-bubble';
            bubble.innerHTML = text.replace(/\n/g, '<br>'); // Format text with line breaks

            messageDiv.appendChild(bubble);
            chatHistory.appendChild(messageDiv);
            chatHistory.style.display = 'block';
            chatHistory.scrollTop = chatHistory.scrollHeight; // Scroll to bottom
        }

        function showError(message) {
            const errorEl = document.getElementById('errorContainer');
            errorEl.textContent = message;
            errorEl.style.display = 'block';
        }

        function hideError() {
            document.getElementById('errorContainer').style.display = 'none';
        }

        // Send transcribed text to backend
        async function sendMessage(text) {
            if (isProcessing) {
                return;
            }

            isProcessing = true;
            updateMicButton('processing');
            updateStatus('Processing your request...', 'processing');
            hideError();

            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        message: text,
                        sessionId: sessionId
                    })
                });

                const data = await response.json();
                
                if (data.sessionId) {
                    sessionId = data.sessionId;
                }

                console.log('AI Response:', data.message);

                // Update status
                updateStatus('Response received. Converting to speech...', 'processing');
                isProcessing = false;
                updateMicButton('');
                
                // Show agent response in transcript area
                showTranscript(data.message, 'agent');
                
                // Convert text to speech and play
                await speakText(data.message);
                
                // Update status after audio playback
                const isCompleted = data.session?.state === 'booking_complete' || 
                                   data.session?.state === 'completed' ||
                                   data.message.includes('booking is confirmed') ||
                                   data.message.includes('rescheduled successfully') ||
                                   data.message.includes('cancelled successfully') ||
                                   data.message.includes('Is there anything else I can help you with');
                
                if (isCompleted) {
                    updateStatus('‚úÖ Action completed! Click microphone for next request.', '');
                } else {
                    updateStatus('Response received. Click microphone to continue.', '');
                }
                
                // Log function calls for debugging
                if (data.functionCalls && data.functionCalls.length > 0) {
                    console.log('Function calls:', data.functionCalls);
                }

            } catch (error) {
                console.error('Error sending message:', error);
                showError('Failed to process your request. Please try again.');
                updateStatus('Error occurred. Click microphone to try again.', '');
                isProcessing = false;
                updateMicButton('');
            }
        }

        // Test microphone access
        async function testMicrophone() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('Microphone access granted');
                stream.getTracks().forEach(track => track.stop()); // Stop the stream
                return true;
            } catch (error) {
                console.error('Microphone access error:', error);
                showError('Microphone access denied. Please allow microphone access and refresh the page.');
                return false;
            }
        }

        // Text-to-Speech - tries Eleven Labs first, falls back to browser TTS
        async function speakText(text) {
            if (!text || text.trim().length === 0) {
                console.warn('[TTS] Empty text, skipping TTS');
                return;
            }

            // Try Eleven Labs first
            try {
                updateStatus('Speaking response...', 'speaking');
                console.log('[TTS] Requesting audio from Eleven Labs:', text.substring(0, 50) + '...');
                
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: text })
                });

                if (!response.ok) {
                    const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
                    console.warn('[TTS] Eleven Labs failed:', response.status, errorData);
                    // Fall through to browser TTS fallback
                    throw new Error('Eleven Labs unavailable');
                }

                const audioBlob = await response.blob();
                console.log('[TTS] Audio received:', audioBlob.size, 'bytes');
                
                if (audioBlob.size === 0) {
                    throw new Error('Received empty audio blob');
                }
                
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = document.getElementById('ttsAudio');
                
                if (!audio) {
                    throw new Error('Audio element not found');
                }
                
                console.log('[TTS] Audio URL created, preparing playback...');
                
                // Wait for audio to finish playing
                await new Promise((resolve, reject) => {
                    let resolved = false;
                    let playAttempted = false;
                    
                    const cleanup = () => {
                        if (!resolved) {
                            resolved = true;
                            URL.revokeObjectURL(audioUrl); // Clean up
                        }
                    };
                    
                    const attemptPlay = () => {
                        if (playAttempted) return;
                        playAttempted = true;
                        
                        console.log('[TTS] Attempting to play audio...');
                        audio.play().then(() => {
                            console.log('[TTS] Audio play() succeeded');
                        }).catch((playError) => {
                            console.error('[TTS] Audio play() failed:', playError);
                            cleanup();
                            reject(playError);
                        });
                    };
                    
                    // Set up event handlers
                    audio.onended = () => {
                        console.log('[TTS] Audio playback completed');
                        cleanup();
                        resolve();
                    };
                    
                    audio.onerror = (error) => {
                        console.error('[TTS] Audio playback error:', error);
                        console.error('[TTS] Audio error details:', {
                            error: audio.error,
                            code: audio.error?.code,
                            message: audio.error?.message
                        });
                        cleanup();
                        reject(new Error(`Audio playback failed: ${audio.error?.message || 'Unknown error'}`));
                    };
                    
                    audio.onloadstart = () => {
                        console.log('[TTS] Audio loading started');
                    };
                    
                    audio.oncanplay = () => {
                        console.log('[TTS] Audio can play');
                        attemptPlay();
                    };
                    
                    audio.onloadeddata = () => {
                        console.log('[TTS] Audio data loaded');
                        attemptPlay();
                    };
                    
                    // Reset and set source
                    audio.pause();
                    audio.currentTime = 0;
                    audio.src = audioUrl;
                    audio.load(); // Force reload
                    
                    // Fallback: try to play after a short delay if events didn't fire
                    setTimeout(() => {
                        if (!resolved && !playAttempted) {
                            console.log('[TTS] Fallback: attempting play after delay');
                            attemptPlay();
                        }
                    }, 500);
                    
                    // Timeout after 30 seconds
                    setTimeout(() => {
                        if (!resolved) {
                            console.warn('[TTS] Audio playback timeout');
                            cleanup();
                            reject(new Error('Audio playback timeout'));
                        }
                    }, 30000);
                });
                
            } catch (error) {
                console.warn('[TTS] Eleven Labs failed, trying browser TTS fallback...');
                
                // Fallback to browser's built-in Web Speech API (completely free, no API key needed)
                if ('speechSynthesis' in window) {
                    try {
                        updateStatus('Speaking response (browser TTS)...', 'speaking');
                        console.log('[TTS] Using browser Web Speech API');
                        
                        // Cancel any ongoing speech
                        window.speechSynthesis.cancel();
                        
                        const utterance = new SpeechSynthesisUtterance(text);
                        utterance.rate = 1.0;
                        utterance.pitch = 1.0;
                        utterance.volume = 1.0;
                        utterance.lang = 'en-US';
                        
                        // Try to use a natural-sounding voice
                        const voices = window.speechSynthesis.getVoices();
                        const preferredVoices = voices.filter(v => 
                            v.name.includes('Samantha') || 
                            v.name.includes('Alex') || 
                            v.name.includes('Google') ||
                            (v.lang.startsWith('en') && !v.localService)
                        );
                        
                        if (preferredVoices.length > 0) {
                            utterance.voice = preferredVoices[0];
                            console.log('[TTS] Using voice:', preferredVoices[0].name);
                        }
                        
                        await new Promise((resolve, reject) => {
                            utterance.onend = () => {
                                console.log('[TTS] Browser TTS completed');
                                resolve();
                            };
                            
                            utterance.onerror = (error) => {
                                console.error('[TTS] Browser TTS error:', error);
                                reject(new Error(`Browser TTS error: ${error.error}`));
                            };
                            
                            window.speechSynthesis.speak(utterance);
                        });
                        
                        console.log('[TTS] Browser TTS playback started');
                        return; // Success with browser TTS
                    } catch (browserError) {
                        console.error('[TTS] Browser TTS also failed:', browserError);
                        showError(`Voice playback failed: ${browserError.message}. Text response is still visible.`);
                    }
                } else {
                    console.error('[TTS] Web Speech API not supported');
                    showError(`Voice playback failed: ${error.message}. Browser TTS not available. Text response is still visible.`);
                }
            }
        }

        // Initialize on page load
        window.addEventListener('load', async () => {
            console.log('Page loaded, initializing...');
            await initSession();
            
            // Test microphone first
            const micAccess = await testMicrophone();
            if (micAccess) {
                initSpeechRecognition();
            } else {
                document.getElementById('micButton').disabled = true;
                document.getElementById('micButton').style.opacity = '0.5';
            }
        });
    </script>
</body>
</html>

